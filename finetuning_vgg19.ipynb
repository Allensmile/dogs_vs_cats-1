{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os, shutil, random, glob\n",
    "import bcolz\n",
    "import keras\n",
    "import keras\n",
    "import keras.preprocessing.image\n",
    "from keras.layers import Input, Flatten, Dense, Dropout, Activation, BatchNormalization\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code below assumes that the train data from the https://www.kaggle.com/c/dogs-vs-cats competition has been downloaded and unzipped into the `train` directory under root of the repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "files = glob.glob('train/*')\n",
    "fnames = [f.split('/')[1] for f in files]\n",
    "\n",
    "os.makedirs('train/cats')\n",
    "os.makedirs('train/dogs')\n",
    "\n",
    "for fname in fnames:\n",
    "    dogs_or_cats = 'dogs' if 'dog' in fname else 'cats'\n",
    "    shutil.move(f'train/{fname}', f'train/{dogs_or_cats}/{fname}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "gen = keras.preprocessing.image.ImageDataGenerator(preprocessing_function=keras.applications.vgg19.preprocess_input)\n",
    "train_data = gen.flow_from_directory('train', target_size=(224, 224), batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_filenames = train_data.filenames\n",
    "bcolz.carray(train_filenames, rootdir='train_filenames', mode='w').flush()\n",
    "train_y = keras.utils.to_categorical(train_data.classes)\n",
    "bcolz.carray(train_y, rootdir='train_y', mode='w').flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_model = keras.applications.vgg19.VGG19(\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    input_shape=(224, 224, 3),\n",
    "    pooling=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_X = base_model.predict_generator(train_data, steps=train_data.n)\n",
    "bcolz.carray(train_X, rootdir='train_X', mode='w').flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trn_ids = np.random.randint(25000, size=6)\n",
    "val_ids = np.delete(np.arange(25000), trn_ids)\n",
    "\n",
    "trn_X = train_X[trn_ids, ...]\n",
    "trn_y = train_y[trn_ids]\n",
    "\n",
    "random_subset = np.random.randint(24994, size=500)\n",
    "val_X = train_X[random_subset, ...]\n",
    "val_y = train_y[random_subset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputs = Input(shape=(7, 7, 512))\n",
    "x = keras.layers.MaxPooling2D(pool_size=(2,2), strides=(2,2))(inputs)\n",
    "x = Flatten()(x)\n",
    "x = Dense(4096)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Dense(2)(x)\n",
    "x = BatchNormalization()(x)\n",
    "predictions = Activation('softmax')(x)\n",
    "\n",
    "model = keras.models.Model(inputs, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(keras.optimizers.Adam(lr=1e-4), 'categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6 samples, validate on 500 samples\n",
      "Epoch 1/40\n",
      "0s - loss: 1.3258 - acc: 0.3333 - val_loss: 4.9667 - val_acc: 0.4740\n",
      "Epoch 2/40\n",
      "0s - loss: 0.2921 - acc: 1.0000 - val_loss: 2.8465 - val_acc: 0.5680\n",
      "Epoch 3/40\n",
      "0s - loss: 0.2375 - acc: 1.0000 - val_loss: 1.9425 - val_acc: 0.6440\n",
      "Epoch 4/40\n",
      "0s - loss: 0.2160 - acc: 1.0000 - val_loss: 1.5847 - val_acc: 0.6720\n",
      "Epoch 5/40\n",
      "0s - loss: 0.2037 - acc: 1.0000 - val_loss: 1.4067 - val_acc: 0.6820\n",
      "Epoch 6/40\n",
      "0s - loss: 0.1957 - acc: 1.0000 - val_loss: 1.2935 - val_acc: 0.6740\n",
      "Epoch 7/40\n",
      "0s - loss: 0.1900 - acc: 1.0000 - val_loss: 1.2052 - val_acc: 0.6780\n",
      "Epoch 8/40\n",
      "0s - loss: 0.1858 - acc: 1.0000 - val_loss: 1.1306 - val_acc: 0.6780\n",
      "Epoch 9/40\n",
      "0s - loss: 0.1825 - acc: 1.0000 - val_loss: 1.0668 - val_acc: 0.6800\n",
      "Epoch 10/40\n",
      "0s - loss: 0.1799 - acc: 1.0000 - val_loss: 1.0111 - val_acc: 0.6840\n",
      "Epoch 11/40\n",
      "0s - loss: 0.1777 - acc: 1.0000 - val_loss: 0.9620 - val_acc: 0.6780\n",
      "Epoch 12/40\n",
      "0s - loss: 0.1759 - acc: 1.0000 - val_loss: 0.9182 - val_acc: 0.6760\n",
      "Epoch 13/40\n",
      "0s - loss: 0.1745 - acc: 1.0000 - val_loss: 0.8790 - val_acc: 0.6740\n",
      "Epoch 14/40\n",
      "0s - loss: 0.1732 - acc: 1.0000 - val_loss: 0.8436 - val_acc: 0.6720\n",
      "Epoch 15/40\n",
      "0s - loss: 0.1721 - acc: 1.0000 - val_loss: 0.8117 - val_acc: 0.6700\n",
      "Epoch 16/40\n",
      "0s - loss: 0.1712 - acc: 1.0000 - val_loss: 0.7828 - val_acc: 0.6700\n",
      "Epoch 17/40\n",
      "0s - loss: 0.1703 - acc: 1.0000 - val_loss: 0.7565 - val_acc: 0.6720\n",
      "Epoch 18/40\n",
      "0s - loss: 0.1696 - acc: 1.0000 - val_loss: 0.7327 - val_acc: 0.6720\n",
      "Epoch 19/40\n",
      "0s - loss: 0.1689 - acc: 1.0000 - val_loss: 0.7109 - val_acc: 0.6720\n",
      "Epoch 20/40\n",
      "0s - loss: 0.1684 - acc: 1.0000 - val_loss: 0.6911 - val_acc: 0.6720\n",
      "Epoch 21/40\n",
      "0s - loss: 0.1678 - acc: 1.0000 - val_loss: 0.6730 - val_acc: 0.6720\n",
      "Epoch 22/40\n",
      "0s - loss: 0.1673 - acc: 1.0000 - val_loss: 0.6564 - val_acc: 0.6740\n",
      "Epoch 23/40\n",
      "0s - loss: 0.1669 - acc: 1.0000 - val_loss: 0.6413 - val_acc: 0.6780\n",
      "Epoch 24/40\n",
      "0s - loss: 0.1665 - acc: 1.0000 - val_loss: 0.6274 - val_acc: 0.6780\n",
      "Epoch 25/40\n",
      "0s - loss: 0.1662 - acc: 1.0000 - val_loss: 0.6148 - val_acc: 0.6780\n",
      "Epoch 26/40\n",
      "0s - loss: 0.1658 - acc: 1.0000 - val_loss: 0.6033 - val_acc: 0.6780\n",
      "Epoch 27/40\n",
      "0s - loss: 0.1655 - acc: 1.0000 - val_loss: 0.5927 - val_acc: 0.6820\n",
      "Epoch 28/40\n",
      "0s - loss: 0.1653 - acc: 1.0000 - val_loss: 0.5831 - val_acc: 0.6840\n",
      "Epoch 29/40\n",
      "0s - loss: 0.1650 - acc: 1.0000 - val_loss: 0.5743 - val_acc: 0.6840\n",
      "Epoch 30/40\n",
      "0s - loss: 0.1648 - acc: 1.0000 - val_loss: 0.5663 - val_acc: 0.6820\n",
      "Epoch 31/40\n",
      "0s - loss: 0.1646 - acc: 1.0000 - val_loss: 0.5590 - val_acc: 0.6820\n",
      "Epoch 32/40\n",
      "0s - loss: 0.1644 - acc: 1.0000 - val_loss: 0.5524 - val_acc: 0.6800\n",
      "Epoch 33/40\n",
      "0s - loss: 0.1642 - acc: 1.0000 - val_loss: 0.5465 - val_acc: 0.6840\n",
      "Epoch 34/40\n",
      "0s - loss: 0.1640 - acc: 1.0000 - val_loss: 0.5411 - val_acc: 0.6860\n",
      "Epoch 35/40\n",
      "0s - loss: 0.1639 - acc: 1.0000 - val_loss: 0.5362 - val_acc: 0.6880\n",
      "Epoch 36/40\n",
      "0s - loss: 0.1637 - acc: 1.0000 - val_loss: 0.5318 - val_acc: 0.6880\n",
      "Epoch 37/40\n",
      "0s - loss: 0.1636 - acc: 1.0000 - val_loss: 0.5279 - val_acc: 0.6920\n",
      "Epoch 38/40\n",
      "0s - loss: 0.1635 - acc: 1.0000 - val_loss: 0.5244 - val_acc: 0.6960\n",
      "Epoch 39/40\n",
      "0s - loss: 0.1634 - acc: 1.0000 - val_loss: 0.5213 - val_acc: 0.6960\n",
      "Epoch 40/40\n",
      "0s - loss: 0.1633 - acc: 1.0000 - val_loss: 0.5186 - val_acc: 0.7000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2fd43a2f98>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=trn_X, y=trn_y, batch_size=6, epochs=40, validation_data=(val_X, val_y), verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's validate on the entire training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_X = train_X[val_ids, ...]\n",
    "val_y = train_y[val_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6 samples, validate on 24994 samples\n",
      "Epoch 1/1\n",
      "13s - loss: 0.1632 - acc: 1.0000 - val_loss: 0.5085 - val_acc: 0.7163\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2fb74bbef0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=trn_X, y=trn_y, batch_size=6, epochs=1, validation_data=(val_X, val_y), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cats/cat.7981.jpg',\n",
       " 'cats/cat.6557.jpg',\n",
       " 'dogs/dog.3869.jpg',\n",
       " 'cats/cat.9467.jpg',\n",
       " 'cats/cat.863.jpg',\n",
       " 'dogs/dog.4733.jpg']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[train_filenames[idx] for idx in trn_ids]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
