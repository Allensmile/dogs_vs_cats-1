{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil, random, glob\n",
    "import bcolz\n",
    "import keras\n",
    "import keras\n",
    "import keras.preprocessing.image\n",
    "from keras.layers import Input, Flatten, Dense, Dropout, Activation, BatchNormalization\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code below assumes that the train data from the https://www.kaggle.com/c/dogs-vs-cats competition has been downloaded and unzipped into the `train` directory under root of the repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "files = glob.glob('train/*')\n",
    "fnames = [f.split('/')[1] for f in files]\n",
    "\n",
    "os.makedirs('train/cats')\n",
    "os.makedirs('train/dogs')\n",
    "\n",
    "for fname in fnames:\n",
    "    dogs_or_cats = 'dogs' if 'dog' in fname else 'cats'\n",
    "    shutil.move(f'train/{fname}', f'train/{dogs_or_cats}/{fname}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "gen = keras.preprocessing.image.ImageDataGenerator(preprocessing_function=keras.applications.vgg19.preprocess_input)\n",
    "train_data = gen.flow_from_directory('train', target_size=(224, 224), batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filenames = train_data.filenames\n",
    "bcolz.carray(train_filenames, rootdir='train_filenames', mode='w').flush()\n",
    "train_y = keras.utils.to_categorical(train_data.classes)\n",
    "bcolz.carray(train_y, rootdir='train_y', mode='w').flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = keras.applications.vgg19.VGG19(\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    input_shape=(224, 224, 3),\n",
    "    pooling=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = base_model.predict_generator(train_data, steps=train_data.n)\n",
    "bcolz.carray(train_X, rootdir='train_X', mode='w').flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_ids = np.random.randint(25000, size=6)\n",
    "val_ids = np.delete(np.arange(25000), random_ids)\n",
    "\n",
    "trn_X = train_X[trn_ids, ...]\n",
    "trn_y = train_y[trn_ids]\n",
    "\n",
    "random_subset = np.random.randint(24994, size=500)\n",
    "val_X = train_X[random_subset, ...]\n",
    "val_y = train_y[random_subset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=(7, 7, 512))\n",
    "x = keras.layers.MaxPooling2D(pool_size=(2,2), strides=(2,2))(inputs)\n",
    "x = Flatten()(x)\n",
    "x = Dense(4096)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Dense(2)(x)\n",
    "x = BatchNormalization()(x)\n",
    "predictions = Activation('softmax')(x)\n",
    "\n",
    "model = keras.models.Model(inputs, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(keras.optimizers.Adam(lr=1e-4), 'categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6 samples, validate on 500 samples\n",
      "Epoch 1/40\n",
      "1s - loss: 0.6546 - acc: 0.5000 - val_loss: 2.9313 - val_acc: 0.6500\n",
      "Epoch 2/40\n",
      "0s - loss: 0.1762 - acc: 1.0000 - val_loss: 1.6842 - val_acc: 0.7440\n",
      "Epoch 3/40\n",
      "0s - loss: 0.1462 - acc: 1.0000 - val_loss: 1.0972 - val_acc: 0.8020\n",
      "Epoch 4/40\n",
      "0s - loss: 0.1407 - acc: 1.0000 - val_loss: 0.7913 - val_acc: 0.8200\n",
      "Epoch 5/40\n",
      "0s - loss: 0.1385 - acc: 1.0000 - val_loss: 0.6022 - val_acc: 0.8420\n",
      "Epoch 6/40\n",
      "0s - loss: 0.1368 - acc: 1.0000 - val_loss: 0.4833 - val_acc: 0.8480\n",
      "Epoch 7/40\n",
      "0s - loss: 0.1353 - acc: 1.0000 - val_loss: 0.4062 - val_acc: 0.8580\n",
      "Epoch 8/40\n",
      "0s - loss: 0.1342 - acc: 1.0000 - val_loss: 0.3549 - val_acc: 0.8700\n",
      "Epoch 9/40\n",
      "0s - loss: 0.1333 - acc: 1.0000 - val_loss: 0.3201 - val_acc: 0.8780\n",
      "Epoch 10/40\n",
      "0s - loss: 0.1326 - acc: 1.0000 - val_loss: 0.2960 - val_acc: 0.8820\n",
      "Epoch 11/40\n",
      "0s - loss: 0.1321 - acc: 1.0000 - val_loss: 0.2794 - val_acc: 0.8800\n",
      "Epoch 12/40\n",
      "0s - loss: 0.1316 - acc: 1.0000 - val_loss: 0.2680 - val_acc: 0.8840\n",
      "Epoch 13/40\n",
      "0s - loss: 0.1312 - acc: 1.0000 - val_loss: 0.2606 - val_acc: 0.8820\n",
      "Epoch 14/40\n",
      "0s - loss: 0.1309 - acc: 1.0000 - val_loss: 0.2560 - val_acc: 0.8840\n",
      "Epoch 15/40\n",
      "0s - loss: 0.1306 - acc: 1.0000 - val_loss: 0.2535 - val_acc: 0.8860\n",
      "Epoch 16/40\n",
      "0s - loss: 0.1303 - acc: 1.0000 - val_loss: 0.2528 - val_acc: 0.8900\n",
      "Epoch 17/40\n",
      "0s - loss: 0.1299 - acc: 1.0000 - val_loss: 0.2533 - val_acc: 0.8920\n",
      "Epoch 18/40\n",
      "0s - loss: 0.1296 - acc: 1.0000 - val_loss: 0.2548 - val_acc: 0.8920\n",
      "Epoch 19/40\n",
      "0s - loss: 0.1293 - acc: 1.0000 - val_loss: 0.2572 - val_acc: 0.8900\n",
      "Epoch 20/40\n",
      "0s - loss: 0.1291 - acc: 1.0000 - val_loss: 0.2601 - val_acc: 0.8900\n",
      "Epoch 21/40\n",
      "0s - loss: 0.1288 - acc: 1.0000 - val_loss: 0.2636 - val_acc: 0.8900\n",
      "Epoch 22/40\n",
      "0s - loss: 0.1286 - acc: 1.0000 - val_loss: 0.2674 - val_acc: 0.8900\n",
      "Epoch 23/40\n",
      "0s - loss: 0.1284 - acc: 1.0000 - val_loss: 0.2714 - val_acc: 0.8880\n",
      "Epoch 24/40\n",
      "0s - loss: 0.1282 - acc: 1.0000 - val_loss: 0.2757 - val_acc: 0.8880\n",
      "Epoch 25/40\n",
      "0s - loss: 0.1280 - acc: 1.0000 - val_loss: 0.2801 - val_acc: 0.8880\n",
      "Epoch 26/40\n",
      "0s - loss: 0.1278 - acc: 1.0000 - val_loss: 0.2846 - val_acc: 0.8920\n",
      "Epoch 27/40\n",
      "0s - loss: 0.1277 - acc: 1.0000 - val_loss: 0.2892 - val_acc: 0.8920\n",
      "Epoch 28/40\n",
      "0s - loss: 0.1275 - acc: 1.0000 - val_loss: 0.2937 - val_acc: 0.8940\n",
      "Epoch 29/40\n",
      "0s - loss: 0.1274 - acc: 1.0000 - val_loss: 0.2983 - val_acc: 0.8940\n",
      "Epoch 30/40\n",
      "0s - loss: 0.1273 - acc: 1.0000 - val_loss: 0.3028 - val_acc: 0.8940\n",
      "Epoch 31/40\n",
      "0s - loss: 0.1272 - acc: 1.0000 - val_loss: 0.3073 - val_acc: 0.8940\n",
      "Epoch 32/40\n",
      "0s - loss: 0.1271 - acc: 1.0000 - val_loss: 0.3117 - val_acc: 0.8940\n",
      "Epoch 33/40\n",
      "0s - loss: 0.1270 - acc: 1.0000 - val_loss: 0.3160 - val_acc: 0.8940\n",
      "Epoch 34/40\n",
      "0s - loss: 0.1270 - acc: 1.0000 - val_loss: 0.3203 - val_acc: 0.8940\n",
      "Epoch 35/40\n",
      "0s - loss: 0.1269 - acc: 1.0000 - val_loss: 0.3245 - val_acc: 0.8940\n",
      "Epoch 36/40\n",
      "0s - loss: 0.1268 - acc: 1.0000 - val_loss: 0.3286 - val_acc: 0.8940\n",
      "Epoch 37/40\n",
      "0s - loss: 0.1267 - acc: 1.0000 - val_loss: 0.3326 - val_acc: 0.8960\n",
      "Epoch 38/40\n",
      "0s - loss: 0.1266 - acc: 1.0000 - val_loss: 0.3366 - val_acc: 0.8960\n",
      "Epoch 39/40\n",
      "0s - loss: 0.1265 - acc: 1.0000 - val_loss: 0.3404 - val_acc: 0.8960\n",
      "Epoch 40/40\n",
      "0s - loss: 0.1265 - acc: 1.0000 - val_loss: 0.3443 - val_acc: 0.8960\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7efca0264780>"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=trn_X, y=trn_y, batch_size=6, epochs=40, validation_data=(val_X, val_y), verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's validate on the entire training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_X = train_X[val_ids, ...]\n",
    "val_y = train_y[val_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6 samples, validate on 24994 samples\n",
      "Epoch 1/1\n",
      "14s - loss: 0.1264 - acc: 1.0000 - val_loss: 0.3422 - val_acc: 0.8997\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7efca097c5c0>"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=trn_X, y=trn_y, batch_size=6, epochs=1, validation_data=(val_X, val_y), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dogs/dog.10586.jpg',\n",
       " 'dogs/dog.3688.jpg',\n",
       " 'cats/cat.12408.jpg',\n",
       " 'dogs/dog.7210.jpg',\n",
       " 'cats/cat.1041.jpg',\n",
       " 'cats/cat.9606.jpg']"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[train_filenames[idx] for idx in trn_ids]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
